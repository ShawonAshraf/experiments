{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f41cf21-e272-4f09-a3b4-8b5e55fe4b6f",
   "metadata": {},
   "source": [
    "Trying out the exercise from: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde1fb70-30ce-46f3-8955-0774bd663514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f81038-bc74-4ab9-b893-a3290494e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    # Tags are: DET - determiner; NN - noun; V - verb\n",
    "    # For example, the word \"The\" is a determiner\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a3ab47-abb8-4fdb-a0b7-7430c65bbb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60ff51a-0027-427c-8bca-ce8786c7542d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 0,\n",
       " 'dog': 1,\n",
       " 'ate': 2,\n",
       " 'the': 3,\n",
       " 'apple': 4,\n",
       " 'Everybody': 5,\n",
       " 'read': 6,\n",
       " 'that': 7,\n",
       " 'book': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "\n",
    "vocabulary = dict()\n",
    "\n",
    "for sentence, _ in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in vocabulary.keys():\n",
    "            vocabulary[word] = len(vocabulary)\n",
    "            \n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3341bd7-82c6-404f-a31b-1f98510c6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = {\"DET\": 0, \"NN\": 1, \"V\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c56da2-0272-433a-bc46-a2034d3e8577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': 0,\n",
       " 'h': 1,\n",
       " 'e': 2,\n",
       " 'd': 3,\n",
       " 'o': 4,\n",
       " 'g': 5,\n",
       " 'a': 6,\n",
       " 't': 7,\n",
       " 'p': 8,\n",
       " 'l': 9,\n",
       " 'E': 10,\n",
       " 'v': 11,\n",
       " 'r': 12,\n",
       " 'y': 13,\n",
       " 'b': 14,\n",
       " 'k': 15}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an alphabet first for a char sequence rep\n",
    "# ignoring case for now\n",
    "alphabet = dict()\n",
    "\n",
    "\n",
    "for sentence, _ in training_data:\n",
    "    for word in sentence:\n",
    "        chars = list(word)\n",
    "        for c in chars:\n",
    "            if c not in alphabet.keys():\n",
    "                alphabet[c] = len(alphabet)\n",
    "        \n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4499b732-22ad-4f64-996c-0c6e4e5694d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "EMBEDDING_DIM = 16\n",
    "HIDDEN_DIM = 30\n",
    "\n",
    "class CharacterBasedTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim=EMBEDDING_DIM,\n",
    "                 hidden_dim=HIDDEN_DIM, \n",
    "                 vocab_size=len(vocabulary), \n",
    "                 tagset_size=len(tagset),\n",
    "                 alphabet_size=len(alphabet)):\n",
    "        \n",
    "        \n",
    "        super(CharacterBasedTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # char rep\n",
    "        self.char_embedding = nn.Embedding(alphabet_size, embedding_dim)\n",
    "        self.char_lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.word_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.tag_lstm = nn.LSTM(embedding_dim + hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "    def forward(self, sentence, characters):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf0af5-592e-4162-af20-bcba9a918635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
