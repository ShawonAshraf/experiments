{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.downloader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/shawon/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights_name = \"word2vec-google-news-300\"\n",
    "model_dl_path = os.path.join(\n",
    "    dl.BASE_DIR, pretrained_weights_name, f\"{pretrained_weights_name}.gz\")\n",
    "\n",
    "\n",
    "if os.path.exists(model_dl_path):\n",
    "    # load model\n",
    "    print(f\"Loading model from {model_dl_path}\")\n",
    "    gnews_embeddings = dl.load(pretrained_weights_name)\n",
    "else:\n",
    "    # download\n",
    "    print(f\"Model will be downloaded at {model_dl_path}\")\n",
    "    gnews_embeddings = dl.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawon/anaconda3/envs/exp/lib/python3.10/site-packages/gensim/models/keyedvectors.py:552: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add vectors for padding and oov\n",
    "padding = np.zeros(300)\n",
    "oov = np.ones(300) * -1\n",
    "\n",
    "gnews_embeddings.add_vector(\"</PAD>\", padding)  # type: ignore\n",
    "gnews_embeddings.add_vector(\"</OOV>\", oov)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = gnews_embeddings.key_to_index[\"</PAD>\"]\n",
    "oov_idx = gnews_embeddings.key_to_index[\"</OOV>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Oneplus/Tweebank\n",
    "from typing import List\n",
    "\n",
    "train_file = os.path.join(\n",
    "    \"/mnt/Others/experiments/datasets/Tweebank-dev/converted/\"\n",
    "    \"en-ud-tweet-train.fixed.conllu\")\n",
    "\n",
    "\n",
    "\n",
    "# need idx 1, 2,3 : word, lemma and pos\n",
    "\n",
    "class ConlluRowInfo:\n",
    "    word: str\n",
    "    lemma: str\n",
    "    pos: str\n",
    "    \n",
    "    def __init__(self, word: str, lemma: str, pos: str) -> None:\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        rep = {\n",
    "            \"word\": self.word,\n",
    "            \"lemma\": self.lemma,\n",
    "            \"pos\": self.pos\n",
    "        }\n",
    "        return str(rep)\n",
    "    \n",
    "\n",
    "\n",
    "class ConlluRow:\n",
    "    info: List[ConlluRowInfo]\n",
    "    # text: str\n",
    "    \n",
    "    def __init__(self, infos: List[ConlluRowInfo]) -> None:\n",
    "        self.info = infos\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"info : {self.info}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import trange, tqdm\n",
    "from typing import Dict, List\n",
    "\n",
    "class TweebankDataset(Dataset):\n",
    "    def __init__(self, filename, pad_idx=pad_idx, w2v_weights=gnews_embeddings) -> None:\n",
    "        self.filename = filename\n",
    "        self.data = list()\n",
    "        self.__read_data()\n",
    "        \n",
    "        self.w2v = w2v_weights\n",
    "        \n",
    "        self.PAD_TOKEN = \"</PAD>\"\n",
    "        self.OOV_TOKEN = \"</OOV>\"\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        \n",
    "        self.MAX_SEQ_LEN = 50 # default value\n",
    "        # self.__find_max_seq_len()\n",
    "        \n",
    "        self.UNIQUE_TAGS = ['PRON', 'NUM', 'NOUN', 'CCONJ', 'ADV', 'SCONJ', \n",
    "                               'ADP', 'AUX', 'PROPN', 'SYM', 'DET', \n",
    "                               'INTJ', 'PUNCT', 'X', 'ADJ', 'VERB', 'PART']\n",
    "        self.tag_dict = dict()\n",
    "        self.__encode_tags()\n",
    "        \n",
    "        self.number_tags = len(self.UNIQUE_TAGS)\n",
    "        \n",
    "        self.vocabulary = self.w2v.index_to_key  # type: ignore\n",
    "            \n",
    "    \n",
    "    def __len__(self) ->  int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:\n",
    "        # ============== collect ===================\n",
    "        words = [i.word for i in self.data[idx].info]\n",
    "        tags = [i.pos for i in self.data[idx].info]\n",
    "        \n",
    "        \n",
    "        # =================== convert using word2vec weights ==========\n",
    "        for idx in range(len(words)):\n",
    "            try:\n",
    "                w2v_idx = self.w2v.key_to_index[words[idx]]  # type: ignore \n",
    "            except KeyError:\n",
    "                w2v_idx = self.w2v.key_to_index[self.OOV_TOKEN] \n",
    "            words[idx] = w2v_idx\n",
    "            tags[idx] = self.tag_dict[tags[idx]]\n",
    "            \n",
    "        \n",
    "        # ============== pad words ===============\n",
    "        # left pad\n",
    "        padded_words = np.ones(self.MAX_SEQ_LEN, dtype=np.int32) * self.pad_idx\n",
    "        padded_words[-len(words):] = words\n",
    "        \n",
    "        padded_tags = np.ones(self.MAX_SEQ_LEN, dtype=np.int32) * self.pad_idx\n",
    "        padded_tags[-len(tags):] = tags\n",
    "        \n",
    "        return {\n",
    "            \"words\": torch.tensor(padded_words),\n",
    "            \"tags\": torch.tensor(padded_tags),\n",
    "        }\n",
    "        \n",
    "    def __find_max_seq_len(self) -> None:\n",
    "        seq_lens = []\n",
    "        \n",
    "        for idx in range(len(self.data)):\n",
    "            words = [i.word for i in self.data[idx].info]\n",
    "            seq_lens.append(len(words))\n",
    "        \n",
    "        \n",
    "        self.MAX_SEQ_LEN = max(seq_lens)\n",
    "        \n",
    "    def __encode_tags(self) -> None:\n",
    "        for idx, tag in enumerate(self.UNIQUE_TAGS):\n",
    "            self.tag_dict[tag] = idx\n",
    "        \n",
    "    def __read_data(self) -> None:\n",
    "        with open(self.filename, \"r\") as f:\n",
    "            data = f.readlines()\n",
    "            \n",
    "            # ============ read the text file =============\n",
    "            lines = list()\n",
    "            buffer = list()\n",
    "            for _, line in tqdm(enumerate(data)):\n",
    "                if line == \"\\n\":\n",
    "                    lines.append(buffer)\n",
    "                    buffer = []\n",
    "                else:\n",
    "                    buffer.append(line)\n",
    "                    \n",
    "            # ============== organize in objects ==============\n",
    "            for idx, line in tqdm(enumerate(lines)):\n",
    "                # from line index 2 and onwards\n",
    "                line_info = list()\n",
    "                for info in line[2:]:\n",
    "                    buffer = info.split(\"\\t\")\n",
    "                \n",
    "                    try:\n",
    "                        word = buffer[1]\n",
    "                        lemma = buffer[2]\n",
    "                        tag = buffer[3]\n",
    "                        \n",
    "                        line_info.append(ConlluRowInfo(word, lemma, tag))\n",
    "                        \n",
    "                    except IndexError:\n",
    "                        print(buffer)\n",
    "                        \n",
    "                \n",
    "                lines[idx] = ConlluRow(line_info)    \n",
    "\n",
    "            self.data = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b1c45aed6d42ab9abe93b3d13a47ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2006e6b2c224143a486506ea9d14ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'words': tensor([3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000,\n",
       "         3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000,\n",
       "         3000000, 3000000, 3000000,   31905, 3000001, 3000001,   12654,   14263,\n",
       "         3000001,      20,     190,      42,   40105,       1,     234,   22860,\n",
       "         3000001,      86,     951,     177,      48,      45,       4,    2604,\n",
       "            2747, 3000001,      20,     248, 3000001, 3000001, 3000001,   10297,\n",
       "         3000001, 3000001], dtype=torch.int32),\n",
       " 'tags': tensor([3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000,\n",
       "         3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000, 3000000,\n",
       "         3000000, 3000000, 3000000,      13,      13,      12,      14,       2,\n",
       "              12,       0,       7,       7,      15,       6,       1,       2,\n",
       "               3,       4,       4,      15,      10,       1,       7,       4,\n",
       "               0,      12,       0,       7,      10,       2,      12,       8,\n",
       "              13,      12], dtype=torch.int32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TweebankDataset(train_file)\n",
    "sample = dataset[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim: int, \n",
    "                 hidden_dim: int,  \n",
    "                 out_size: int,\n",
    "                 pad_idx=pad_idx, \n",
    "                 freeze_embeddings=True, \n",
    "                 w2v_weights=gnews_embeddings) -> None:\n",
    "        \n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.taget_size = out_size\n",
    "        \n",
    "        \n",
    "        embedding_tensors = torch.from_numpy(w2v_weights.vectors) # type: ignore        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(\n",
    "            embedding_tensors, freeze=freeze_embeddings, padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        \n",
    "        self.attention =  nn.MultiheadAttention(hidden_dim * 2, num_heads=4, dropout=0.1, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim * 2, out_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        \n",
    "    def forward(self, words):\n",
    "        embeds = self.word_embeddings(words)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        linear_out = self.linear(attn_out)\n",
    "        linear_out = self.relu(linear_out)\n",
    "        logits = self.log_softmax(linear_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 50])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMTagger(embedding_dim=300, hidden_dim=100,  out_size=dataset.MAX_SEQ_LEN)\n",
    "\n",
    "# run a sample forward pass\n",
    "sample = dataset[42]\n",
    "out = model(sample[\"words\"])\n",
    "out.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-3.8585, -3.8886, -3.8952, -3.8832, -3.8592, -3.8913, -3.9326, -3.9326,\n",
       "        -3.9326, -3.8963, -3.9277, -3.9326, -3.9071, -3.9326, -3.9326, -3.9326,\n",
       "        -3.9175, -3.8422, -3.9305, -3.9048, -3.9326, -3.9326, -3.8916, -3.9326,\n",
       "        -3.9022, -3.9326, -3.9080, -3.8582, -3.9269, -3.8869, -3.9326, -3.9310,\n",
       "        -3.9231, -3.8810, -3.9326, -3.9235, -3.8713, -3.9326, -3.9326, -3.8674,\n",
       "        -3.9326, -3.9320, -3.8715, -3.9233, -3.9326, -3.9233, -3.8729, -3.9326,\n",
       "        -3.9326, -3.9326], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([ 6, 35, 16, 15,  6,  8, 18, 18, 18, 12, 41, 18, 11, 18, 18, 18, 43, 12,\n",
       "         9, 11, 18, 18, 27, 18,  5, 18, 43, 34, 11, 32, 18, 21, 12, 28, 18, 11,\n",
       "        18, 18, 18, 34, 18, 13, 12, 16, 18, 16, 44, 18, 18, 18]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3dec19baf049a3985d7898f645a7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45690d7d48e64ca081fab17e88c42d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d03bd3df9f484b9fc427c9cde344f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc2b4bff2dd48faa0be8e6c07efe3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 128\n",
    "dl_args = {\n",
    "    # \"pin_memory\": True,\n",
    "    \"batch_size\": bs\n",
    "}\n",
    "\n",
    "\n",
    "training_set = dataset\n",
    "validation_set = TweebankDataset(\"/mnt/Others/experiments/datasets/Tweebank-dev/converted/en-ud-tweet-dev.fixed.conllu\")\n",
    "test_set = TweebankDataset(\"/mnt/Others/experiments/datasets/Tweebank-dev/converted/en-ud-tweet-test.fixed.conllu\")\n",
    "\n",
    "train_loader = DataLoader(training_set, shuffle=True, **dl_args)\n",
    "val_loader = DataLoader(validation_set, shuffle=False, **dl_args)\n",
    "test_loader = DataLoader(test_set, shuffle=False, **dl_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0adf06f02a497a899283b6ae904739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Target 3000000 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m     logits \u001b[39m=\u001b[39m model(words)\n\u001b[1;32m     28\u001b[0m     \u001b[39m# loss\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     loss \u001b[39m=\u001b[39m criterion(logits, tags)\n\u001b[1;32m     32\u001b[0m \u001b[39m# ======== validation ==============\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m steps \u001b[39m%\u001b[39m run_validation_every_n_step \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/exp/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/exp/lib/python3.10/site-packages/torch/nn/modules/loss.py:216\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnll_loss(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/anaconda3/envs/exp/lib/python3.10/site-packages/torch/nn/functional.py:2701\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2699\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2700\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2701\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mnll_loss_nd(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 3000000 is out of bounds."
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(params=model.parameters())\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "run_validation_every_n_step = 1\n",
    "\n",
    "# fp16\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "epochs = 300\n",
    "for e in trange(epochs):\n",
    "\n",
    "    steps = 0\n",
    "    for batch in train_loader:\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "        \n",
    "        words = batch[\"words\"]\n",
    "        tags = batch[\"tags\"].long()\n",
    "        \n",
    "        # send data to device\n",
    "        words = words.to(device)\n",
    "        tags = tags.to(device)\n",
    "        \n",
    "        # zero out optimizer to accumulate new grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            logits = model(words)\n",
    "            # loss\n",
    "            loss = criterion(logits, tags)\n",
    "        \n",
    "        \n",
    "        # ======== validation ==============\n",
    "        if steps % run_validation_every_n_step == 0:\n",
    "            val_losses = []\n",
    "            \n",
    "            # switch context\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    words = val_batch[\"words\"]\n",
    "                    tags = val_batch[\"tags\"].long()\n",
    "                    \n",
    "                    words = words.to(device)\n",
    "                    tags = tags.to(device)\n",
    "                    \n",
    "                    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                        logits = model(words)\n",
    "                        val_loss = criterion(logits, tags)\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "                # log\n",
    "                print(f\"Epoch:: {{e + 1}}/{{epochs}} Step:: {steps}\")\n",
    "                print(f\"Train Loss:: {loss} __________ Val Loss:: {torch.mean(torch.tensor(val_losses))}\")\n",
    "        \n",
    "        # switch context\n",
    "        model.train()\n",
    "        scaler.scale(loss).backward()  # type: ignore\n",
    "        # loss.backward()\n",
    "        scaler.step(optimizer)\n",
    "        # optimizer.step()\n",
    "        scaler.update()\n",
    "        steps += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5383723a85d76e4e9cac0d136e01f6d8a177dc9dc4ee2b9a35edd51227ec1b17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
