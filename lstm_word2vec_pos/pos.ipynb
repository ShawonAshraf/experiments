{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/shawon/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as dl\n",
    "\n",
    "pretrained_weights_name = \"word2vec-google-news-300\"\n",
    "model_dl_path = os.path.join(\n",
    "    dl.BASE_DIR, pretrained_weights_name, f\"{pretrained_weights_name}.gz\")\n",
    "\n",
    "\n",
    "if os.path.exists(model_dl_path):\n",
    "    # load model\n",
    "    print(f\"Loading model from {model_dl_path}\")\n",
    "    gnews_embeddings = dl.load(pretrained_weights_name)\n",
    "else:\n",
    "    # download\n",
    "    print(f\"Model will be downloaded at {model_dl_path}\")\n",
    "    gnews_embeddings = dl.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawon/anaconda3/envs/exp/lib/python3.10/site-packages/gensim/models/keyedvectors.py:552: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# add PAD to embeddings\n",
    "\n",
    "# 0 padding, 300 embedding dims\n",
    "gnews_embeddings.add_vector(\"<PAD>\", np.zeros(300))\n",
    "\n",
    "# need it later for loading the embeddings in pytorch model\n",
    "padding_idx = len(gnews_embeddings.index_to_key) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Oneplus/Tweebank\n",
    "\n",
    "train_file = os.path.join(\n",
    "    \"/mnt/Others/experiments/datasets/Tweebank-dev/converted/\"\n",
    "    \"en-ud-tweet-train.fixed.conllu\")\n",
    "\n",
    "# assert os.path.exists(train_file)\n",
    "\n",
    "with open(train_file) as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# tweet_id = feb_jul_16.1463316480\\n',\n",
       " \"# text = RT @USER991: Dear diary,       I've been rapping in 3 accents and no longer know which one is truly mine. I am a sadting - Drake URL217…\\n\",\n",
       " '1\\tRT\\trt\\tX\\t_\\t_\\t10\\tdiscourse\\t_\\t_\\n',\n",
       " '2\\t@USER991\\t@USER\\tX\\t_\\t_\\t1\\tdiscourse\\t_\\tSpaceAfter=No\\n',\n",
       " '3\\t:\\t:\\tPUNCT\\t_\\t_\\t1\\tpunct\\t_\\t_\\n',\n",
       " '4\\tDear\\tdear\\tADJ\\t_\\t_\\t5\\tamod\\t_\\t_\\n',\n",
       " '5\\tdiary\\tdiary\\tNOUN\\t_\\t_\\t10\\tvocative\\t_\\tSpaceAfter=No\\n',\n",
       " '6\\t,\\t,\\tPUNCT\\t_\\t_\\t10\\tpunct\\t_\\t_\\n',\n",
       " '7\\tI\\ti\\tPRON\\t_\\t_\\t10\\tnsubj\\t_\\tSpaceAfter=No\\n',\n",
       " \"8\\t've\\t've\\tAUX\\t_\\t_\\t10\\taux\\t_\\t_\\n\",\n",
       " '9\\tbeen\\tbe\\tAUX\\t_\\t_\\t10\\taux\\t_\\t_\\n',\n",
       " '10\\trapping\\trap\\tVERB\\t_\\t_\\t0\\troot\\t_\\t_\\n',\n",
       " '11\\tin\\tin\\tADP\\t_\\t_\\t13\\tcase\\t_\\t_\\n',\n",
       " '12\\t3\\tNUMBER\\tNUM\\t_\\t_\\t13\\tnummod\\t_\\t_\\n',\n",
       " '13\\taccents\\taccent\\tNOUN\\t_\\t_\\t10\\tobl\\t_\\t_\\n',\n",
       " '14\\tand\\tand\\tCCONJ\\t_\\t_\\t17\\tcc\\t_\\t_\\n',\n",
       " '15\\tno\\tno\\tADV\\t_\\t_\\t16\\tadvmod\\t_\\t_\\n',\n",
       " '16\\tlonger\\tlonger\\tADV\\t_\\t_\\t17\\tadvmod\\t_\\t_\\n',\n",
       " '17\\tknow\\tknow\\tVERB\\t_\\t_\\t10\\tconj\\t_\\t_\\n',\n",
       " '18\\twhich\\twhich\\tDET\\t_\\t_\\t19\\tdet\\t_\\t_\\n',\n",
       " '19\\tone\\tone\\tNUM\\t_\\t_\\t22\\tnsubj\\t_\\t_\\n',\n",
       " '20\\tis\\tbe\\tAUX\\t_\\t_\\t22\\tcop\\t_\\t_\\n',\n",
       " '21\\ttruly\\ttruly\\tADV\\t_\\t_\\t22\\tadvmod\\t_\\t_\\n',\n",
       " '22\\tmine\\tmine\\tPRON\\t_\\t_\\t17\\tccomp\\t_\\tSpaceAfter=No\\n',\n",
       " '23\\t.\\t.\\tPUNCT\\t_\\t_\\t10\\tpunct\\t_\\t_\\n',\n",
       " '24\\tI\\ti\\tPRON\\t_\\t_\\t27\\tnsubj\\t_\\t_\\n',\n",
       " '25\\tam\\tbe\\tAUX\\t_\\t_\\t27\\tcop\\t_\\t_\\n',\n",
       " '26\\ta\\ta\\tDET\\t_\\t_\\t27\\tdet\\t_\\t_\\n',\n",
       " '27\\tsadting\\tsadting\\tNOUN\\t_\\t_\\t10\\tparataxis\\t_\\t_\\n',\n",
       " '28\\t-\\t-\\tPUNCT\\t_\\t_\\t27\\tpunct\\t_\\t_\\n',\n",
       " '29\\tDrake\\tdrake\\tPROPN\\t_\\t_\\t27\\tparataxis\\t_\\t_\\n',\n",
       " '30\\tURL217\\tURL\\tX\\t_\\t_\\t27\\tlist\\t_\\tSpaceAfter=No\\n',\n",
       " '31\\t…\\t…\\tPUNCT\\t_\\t_\\t27\\tpunct\\t_\\tSpaceAfter=\\\\n\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break line at every \"\\n\"\n",
    "tweets = list()\n",
    "buffer = list()\n",
    "for idx, tw in enumerate(data):\n",
    "    if tw == \"\\n\":\n",
    "        # one partition here\n",
    "        tweets.append(buffer)\n",
    "        buffer = []\n",
    "    else:\n",
    "        # keep appending\n",
    "        buffer.append(tw)\n",
    "        \n",
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4', 'Dear', 'dear', 'ADJ', '_', '_', '5', 'amod', '_', '_\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format for tokens\n",
    "# number - word - lemma - pos - _ - _ - id - role, -, - \n",
    "\n",
    "'4\\tDear\\tdear\\tADJ\\t_\\t_\\t5\\tamod\\t_\\t_\\n'.split(\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need idx 1, 2,3 : word, lemma and pos\n",
    "\n",
    "class ConlluRowInfo:\n",
    "    word: str\n",
    "    lemma: str\n",
    "    pos: str\n",
    "    \n",
    "    def __init__(self, word: str, lemma: str, pos: str) -> None:\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        rep = {\n",
    "            \"word\": self.word,\n",
    "            \"lemma\": self.lemma,\n",
    "            \"pos\": self.pos\n",
    "        }\n",
    "        return str(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class ConlluRow:\n",
    "    info: List[ConlluRowInfo]\n",
    "    # text: str\n",
    "    \n",
    "    def __init__(self, infos: List[ConlluRowInfo]) -> None:\n",
    "        self.info = infos\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"info : {self.info}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_tweets = list()\n",
    "\n",
    "for tweet in tweets:\n",
    "    # text = tweet[1].replace(\"# text = \", \"\")\n",
    "    info_in_tweet = list()\n",
    "    # start from idx 2\n",
    "    for infos in tweet[2:]:\n",
    "        buffer = infos.split(\"\\t\")\n",
    "        try:\n",
    "            word = buffer[1]\n",
    "            lemma = buffer[2]\n",
    "            tag = buffer[3]\n",
    "            info_in_tweet.append(ConlluRowInfo(word, lemma, tag))\n",
    "        except IndexError:\n",
    "            print(buffer)\n",
    "        except AttributeError as e:\n",
    "            print(e.name)\n",
    "    structured_tweets.append(ConlluRow(info_in_tweet))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.8046875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(structured_tweets) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to define the torch dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import trange, tqdm\n",
    "from typing import Dict, List\n",
    "\n",
    "class TweebankDataset(Dataset):\n",
    "    def __init__(self, filename, w2v_weights=gnews_embeddings) -> None:\n",
    "        self.filename = filename\n",
    "        \n",
    "        self.w2v = w2v_weights\n",
    "        self.data = list()\n",
    "        self.__read_data()\n",
    "        \n",
    "        self.MAX_SEQ_LEN = 50 # default value\n",
    "        # self.__find_max_seq_len()\n",
    "        \n",
    "        self.UNIQUE_TAGS = ['PRON', 'NUM', 'NOUN', 'CCONJ', 'ADV', 'SCONJ', \n",
    "                               'ADP', 'AUX', 'PROPN', 'SYM', 'DET', \n",
    "                               'INTJ', 'PUNCT', 'X', 'ADJ', 'VERB', 'PART', \"<PAD>\"]\n",
    "        self.tag_dict = dict()\n",
    "        self.__encode_tags()\n",
    "        \n",
    "        self.number_tags = len(self.UNIQUE_TAGS)\n",
    "        \n",
    "        self.vocabulary = self.w2v.index_to_key  # type: ignore\n",
    "            \n",
    "    \n",
    "    def __len__(self) ->  int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:\n",
    "        # ============== collect ===================\n",
    "        words = [i.word for i in self.data[idx].info]\n",
    "        # lemmas = [i.lemma for i in self.data[idx].info]\n",
    "        tags = [i.pos for i in self.data[idx].info]\n",
    "        \n",
    "        \n",
    "        # =================== convert using word2vec weights ==========\n",
    "        for idx in range(len(words)):\n",
    "            try:\n",
    "                w2v_idx = self.w2v.key_to_index[words[idx]]  # type: ignore \n",
    "            except KeyError:\n",
    "                w2v_idx = 0 # </s>\n",
    "            words[idx] = w2v_idx\n",
    "            tags[idx] = self.tag_dict[tags[idx]]\n",
    "            \n",
    "        \n",
    "        # ============== pad words ===============\n",
    "        # left pad\n",
    "        padded_words = np.zeros(self.MAX_SEQ_LEN, dtype=np.int32)\n",
    "        padded_words[-len(words):] = words\n",
    "        \n",
    "        # ============== pad tags =================\n",
    "        padded_tags = np.ones(self.MAX_SEQ_LEN, dtype=np.int32) * self.tag_dict.get(\"<PAD>\")  # type: ignore        \n",
    "        padded_tags[-len(tags):] = tags\n",
    "        \n",
    "        return {\n",
    "            \"words\": torch.tensor(padded_words),\n",
    "            \"tags\": torch.tensor(padded_tags),\n",
    "        }\n",
    "        \n",
    "    def __find_max_seq_len(self) -> None:\n",
    "        seq_lens = []\n",
    "        \n",
    "        for idx in range(len(self.data)):\n",
    "            words = [i.word for i in self.data[idx].info]\n",
    "            seq_lens.append(len(words))\n",
    "        \n",
    "        \n",
    "        self.MAX_SEQ_LEN = max(seq_lens)\n",
    "        \n",
    "    def __encode_tags(self) -> None:\n",
    "        for idx, tag in enumerate(self.UNIQUE_TAGS):\n",
    "            self.tag_dict[tag] = idx\n",
    "        \n",
    "    def __read_data(self) -> None:\n",
    "        with open(self.filename, \"r\") as f:\n",
    "            data = f.readlines()\n",
    "            \n",
    "            # ============ read the text file =============\n",
    "            lines = list()\n",
    "            buffer = list()\n",
    "            for _, line in tqdm(enumerate(data)):\n",
    "                if line == \"\\n\":\n",
    "                    lines.append(buffer)\n",
    "                    buffer = []\n",
    "                else:\n",
    "                    buffer.append(line)\n",
    "                    \n",
    "            # ============== organize in objects ==============\n",
    "            for idx, line in tqdm(enumerate(lines)):\n",
    "                # from line index 2 and onwards\n",
    "                line_info = list()\n",
    "                for info in line[2:]:\n",
    "                    buffer = info.split(\"\\t\")\n",
    "                \n",
    "                    try:\n",
    "                        word = buffer[1]\n",
    "                        lemma = buffer[2]\n",
    "                        tag = buffer[3]\n",
    "                        \n",
    "                        line_info.append(ConlluRowInfo(word, lemma, tag))\n",
    "                        \n",
    "                    except IndexError:\n",
    "                        print(buffer)\n",
    "                        \n",
    "                \n",
    "                lines[idx] = ConlluRow(line_info)    \n",
    "\n",
    "            self.data = lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc0e899848341a482bb1dd02d764663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8790cd79763f4c99acfa12aa28b950ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'words': tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0, 31905,\n",
       "             0,     0, 12654, 14263,     0,    20,   190,    42, 40105,     1,\n",
       "           234, 22860,     0,    86,   951,   177,    48,    45,     4,  2604,\n",
       "          2747,     0,    20,   248,     0,     0,     0, 10297,     0,     0],\n",
       "        dtype=torch.int32),\n",
       " 'tags': tensor([17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 13, 13, 12, 14,  2, 12,  0,  7,  7, 15,  6,  1,  2,  3,  4,  4, 15,\n",
       "         10,  1,  7,  4,  0, 12,  0,  7, 10,  2, 12,  8, 13, 12],\n",
       "        dtype=torch.int32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TweebankDataset(train_file)\n",
    "sample = dataset[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRON': 0,\n",
       " 'NUM': 1,\n",
       " 'NOUN': 2,\n",
       " 'CCONJ': 3,\n",
       " 'ADV': 4,\n",
       " 'SCONJ': 5,\n",
       " 'ADP': 6,\n",
       " 'AUX': 7,\n",
       " 'PROPN': 8,\n",
       " 'SYM': 9,\n",
       " 'DET': 10,\n",
       " 'INTJ': 11,\n",
       " 'PUNCT': 12,\n",
       " 'X': 13,\n",
       " 'ADJ': 14,\n",
       " 'VERB': 15,\n",
       " 'PART': 16,\n",
       " '<PAD>': 17}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackabuse.com/python-how-to-flatten-list-of-lists/\n",
    "\n",
    "\n",
    "# import itertools\n",
    "\n",
    "# all_tags = [data[\"tags\"] for data in dataset]\n",
    "# all_tags = list(itertools.chain(*all_tags))\n",
    "# unique_tags = set(all_tags)\n",
    "# print(list(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79667925200249908b6f00da229831d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa13245d3894954846d629d73a86311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e70a5eb0f044bb9723552c86a58336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7979f6bd3e354e9fbf05eabd439b4639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 128\n",
    "dl_args = {\n",
    "    \"pin_memory\": True,\n",
    "    \"batch_size\": bs\n",
    "}\n",
    "\n",
    "\n",
    "training_set = dataset\n",
    "validation_set = TweebankDataset(\"/mnt/Others/experiments/datasets/Tweebank-dev/converted/en-ud-tweet-dev.fixed.conllu\")\n",
    "test_set = TweebankDataset(\"/mnt/Others/experiments/datasets/Tweebank-dev/converted/en-ud-tweet-test.fixed.conllu\")\n",
    "\n",
    "train_loader = DataLoader(training_set, shuffle=True, **dl_args)\n",
    "val_loader = DataLoader(validation_set, shuffle=False, **dl_args)\n",
    "test_loader = DataLoader(test_set, shuffle=False, **dl_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert training_set.tag_dict == validation_set.tag_dict == test_set.tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim: int, \n",
    "                 hidden_dim: int,  \n",
    "                 tagset_size: int,\n",
    "                 padding_idx=padding_idx, \n",
    "                 freeze_embeddings=True, \n",
    "                 w2v_weights=gnews_embeddings) -> None:\n",
    "        \n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.taget_size = tagset_size\n",
    "        \n",
    "        \n",
    "        embedding_tensors = torch.from_numpy(w2v_weights.vectors) # type: ignore        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(\n",
    "            embedding_tensors, freeze=freeze_embeddings, padding_idx=padding_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        \n",
    "        self.attention =  nn.MultiheadAttention(hidden_dim * 2, num_heads=4, dropout=0.1, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "\n",
    "        \n",
    "    def forward(self, words):\n",
    "        embeds = self.word_embeddings(words)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        \n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        relu_out = self.relu(attn_out)\n",
    "        \n",
    "        linear_out = self.linear(relu_out)\n",
    "\n",
    "        logits = F.log_softmax(linear_out, dim=-1)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset_size = len(dataset.UNIQUE_TAGS)\n",
    "model = LSTMTagger(embedding_dim=300, hidden_dim=100,  tagset_size=tagset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out :: torch.Size([1, 18, 50])\n",
      "tags :: torch.Size([1, 50])\n",
      "tensor(2.9070)\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "# run a sample forward pass\n",
    "sample = dataset[42]\n",
    "\n",
    "with torch.no_grad():\n",
    "    words = sample[\"words\"].unsqueeze(0)\n",
    "    tags = sample[\"tags\"].unsqueeze(0).long()\n",
    "    \n",
    "    out = model(words)\n",
    "    \n",
    "    # apparently nllloss expects inputs in shape (bs, n_classes, feature_dims.......)\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss\n",
    "    out = rearrange(out, \"1 words probas -> 1 probas words\")\n",
    "    \n",
    "    print(f\"out :: {out.size()}\")\n",
    "    print(f\"tags :: {tags.size()}\")\n",
    "    \n",
    "# sample_loss = F.nll_loss(out, tags, ignore_index=17)\n",
    "sample_loss = nn.NLLLoss(ignore_index=17)\n",
    "print(sample_loss(input=out, target=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 2, 1])\n",
      "tensor([[ 0.2334,  0.0230,  0.1231],\n",
      "        [-1.6351, -0.1873,  1.0384],\n",
      "        [-0.6161,  0.2585,  0.2205],\n",
      "        [ 0.5543, -2.7604,  1.0863]])\n",
      "tensor(2.3289)\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/loss-function-for-multi-class-with-probabilities-as-output/60866\n",
    "\n",
    "x = torch.tensor([[0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0]], dtype=torch.int32)\n",
    "_, i = torch.max(x, dim=-1)\n",
    "\n",
    "print(i)\n",
    "\n",
    "y = torch.randn((4, 3), dtype=torch.float32)\n",
    "print(y)\n",
    "\n",
    "print(F.nll_loss(F.log_softmax(y, dim=-1), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c03bfd17bc4415995fbb63d2734ad2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:: [1]/[50] Step:: 0\n",
      "Train Loss:: 2.8931610584259033 __________ Val Loss:: 2.892637014389038\n",
      "Epoch:: [1]/[50] Step:: 10\n",
      "Train Loss:: 2.643974781036377 __________ Val Loss:: 2.6518373489379883\n",
      "Epoch:: [2]/[50] Step:: 0\n",
      "Train Loss:: 2.6407041549682617 __________ Val Loss:: 2.648193597793579\n",
      "Epoch:: [2]/[50] Step:: 10\n",
      "Train Loss:: 2.5916478633880615 __________ Val Loss:: 2.601397752761841\n",
      "Epoch:: [3]/[50] Step:: 0\n",
      "Train Loss:: 2.6009249687194824 __________ Val Loss:: 2.5942699909210205\n",
      "Epoch:: [3]/[50] Step:: 10\n",
      "Train Loss:: 2.5720574855804443 __________ Val Loss:: 2.5839450359344482\n",
      "Epoch:: [4]/[50] Step:: 0\n",
      "Train Loss:: 2.5788092613220215 __________ Val Loss:: 2.5827953815460205\n",
      "Epoch:: [4]/[50] Step:: 10\n",
      "Train Loss:: 2.5469937324523926 __________ Val Loss:: 2.5780766010284424\n",
      "Epoch:: [5]/[50] Step:: 0\n",
      "Train Loss:: 2.5778305530548096 __________ Val Loss:: 2.576300859451294\n",
      "Epoch:: [5]/[50] Step:: 10\n",
      "Train Loss:: 2.5157692432403564 __________ Val Loss:: 2.5433881282806396\n",
      "Epoch:: [6]/[50] Step:: 0\n",
      "Train Loss:: 2.527580499649048 __________ Val Loss:: 2.508373498916626\n",
      "Epoch:: [6]/[50] Step:: 10\n",
      "Train Loss:: 2.3864214420318604 __________ Val Loss:: 2.3446943759918213\n",
      "Epoch:: [7]/[50] Step:: 0\n",
      "Train Loss:: 2.267059803009033 __________ Val Loss:: 2.2801287174224854\n",
      "Epoch:: [7]/[50] Step:: 10\n",
      "Train Loss:: 2.0887768268585205 __________ Val Loss:: 2.0877816677093506\n",
      "Epoch:: [8]/[50] Step:: 0\n",
      "Train Loss:: 2.111009359359741 __________ Val Loss:: 2.0514638423919678\n",
      "Epoch:: [8]/[50] Step:: 10\n",
      "Train Loss:: 1.9176623821258545 __________ Val Loss:: 1.9575449228286743\n",
      "Epoch:: [9]/[50] Step:: 0\n",
      "Train Loss:: 1.9034695625305176 __________ Val Loss:: 1.9034661054611206\n",
      "Epoch:: [9]/[50] Step:: 10\n",
      "Train Loss:: 1.8494724035263062 __________ Val Loss:: 1.812509536743164\n",
      "Epoch:: [10]/[50] Step:: 0\n",
      "Train Loss:: 1.84213387966156 __________ Val Loss:: 1.796295166015625\n",
      "Epoch:: [10]/[50] Step:: 10\n",
      "Train Loss:: 1.7496088743209839 __________ Val Loss:: 1.717246413230896\n",
      "Epoch:: [11]/[50] Step:: 0\n",
      "Train Loss:: 1.6797035932540894 __________ Val Loss:: 1.6982954740524292\n",
      "Epoch:: [11]/[50] Step:: 10\n",
      "Train Loss:: 1.626569390296936 __________ Val Loss:: 1.629947543144226\n",
      "Epoch:: [12]/[50] Step:: 0\n",
      "Train Loss:: 1.5765862464904785 __________ Val Loss:: 1.6337084770202637\n",
      "Epoch:: [12]/[50] Step:: 10\n",
      "Train Loss:: 1.5194408893585205 __________ Val Loss:: 1.5643788576126099\n",
      "Epoch:: [13]/[50] Step:: 0\n",
      "Train Loss:: 1.5633518695831299 __________ Val Loss:: 1.5306366682052612\n",
      "Epoch:: [13]/[50] Step:: 10\n",
      "Train Loss:: 1.4054654836654663 __________ Val Loss:: 1.4552373886108398\n",
      "Epoch:: [14]/[50] Step:: 0\n",
      "Train Loss:: 1.4383655786514282 __________ Val Loss:: 1.4405417442321777\n",
      "Epoch:: [14]/[50] Step:: 10\n",
      "Train Loss:: 1.3681104183197021 __________ Val Loss:: 1.3926607370376587\n",
      "Epoch:: [15]/[50] Step:: 0\n",
      "Train Loss:: 1.300456166267395 __________ Val Loss:: 1.3562850952148438\n",
      "Epoch:: [15]/[50] Step:: 10\n",
      "Train Loss:: 1.2921556234359741 __________ Val Loss:: 1.2963839769363403\n",
      "Epoch:: [16]/[50] Step:: 0\n",
      "Train Loss:: 1.2701683044433594 __________ Val Loss:: 1.2629531621932983\n",
      "Epoch:: [16]/[50] Step:: 10\n",
      "Train Loss:: 1.1734538078308105 __________ Val Loss:: 1.1890658140182495\n",
      "Epoch:: [17]/[50] Step:: 0\n",
      "Train Loss:: 1.0851061344146729 __________ Val Loss:: 1.1743978261947632\n",
      "Epoch:: [17]/[50] Step:: 10\n",
      "Train Loss:: 1.0765265226364136 __________ Val Loss:: 1.1172372102737427\n",
      "Epoch:: [18]/[50] Step:: 0\n",
      "Train Loss:: 1.0523890256881714 __________ Val Loss:: 1.0962834358215332\n",
      "Epoch:: [18]/[50] Step:: 10\n",
      "Train Loss:: 0.9955943822860718 __________ Val Loss:: 1.0647131204605103\n",
      "Epoch:: [19]/[50] Step:: 0\n",
      "Train Loss:: 0.929992139339447 __________ Val Loss:: 1.0374364852905273\n",
      "Epoch:: [19]/[50] Step:: 10\n",
      "Train Loss:: 0.9447159171104431 __________ Val Loss:: 1.021461009979248\n",
      "Epoch:: [20]/[50] Step:: 0\n",
      "Train Loss:: 0.9256110191345215 __________ Val Loss:: 1.0142877101898193\n",
      "Epoch:: [20]/[50] Step:: 10\n",
      "Train Loss:: 0.9126276969909668 __________ Val Loss:: 0.9979961514472961\n",
      "Epoch:: [21]/[50] Step:: 0\n",
      "Train Loss:: 0.8268619775772095 __________ Val Loss:: 0.9761276245117188\n",
      "Epoch:: [21]/[50] Step:: 10\n",
      "Train Loss:: 0.8693718910217285 __________ Val Loss:: 0.9753230214118958\n",
      "Epoch:: [22]/[50] Step:: 0\n",
      "Train Loss:: 0.8595077395439148 __________ Val Loss:: 0.9622530937194824\n",
      "Epoch:: [22]/[50] Step:: 10\n",
      "Train Loss:: 0.8594126105308533 __________ Val Loss:: 0.9520969986915588\n",
      "Epoch:: [23]/[50] Step:: 0\n",
      "Train Loss:: 0.8534804582595825 __________ Val Loss:: 0.9602534770965576\n",
      "Epoch:: [23]/[50] Step:: 10\n",
      "Train Loss:: 0.8001285195350647 __________ Val Loss:: 0.9348297715187073\n",
      "Epoch:: [24]/[50] Step:: 0\n",
      "Train Loss:: 0.7381193041801453 __________ Val Loss:: 0.9342591762542725\n",
      "Epoch:: [24]/[50] Step:: 10\n",
      "Train Loss:: 0.7607499361038208 __________ Val Loss:: 0.91932612657547\n",
      "Epoch:: [25]/[50] Step:: 0\n",
      "Train Loss:: 0.7317759990692139 __________ Val Loss:: 0.9142902493476868\n",
      "Epoch:: [25]/[50] Step:: 10\n",
      "Train Loss:: 0.6937704682350159 __________ Val Loss:: 0.8907286524772644\n",
      "Epoch:: [26]/[50] Step:: 0\n",
      "Train Loss:: 0.7459797859191895 __________ Val Loss:: 0.9081605076789856\n",
      "Epoch:: [26]/[50] Step:: 10\n",
      "Train Loss:: 0.7147430777549744 __________ Val Loss:: 0.8858284950256348\n",
      "Epoch:: [27]/[50] Step:: 0\n",
      "Train Loss:: 0.6791885495185852 __________ Val Loss:: 0.8733189702033997\n",
      "Epoch:: [27]/[50] Step:: 10\n",
      "Train Loss:: 0.7506276369094849 __________ Val Loss:: 0.8989777565002441\n",
      "Epoch:: [28]/[50] Step:: 0\n",
      "Train Loss:: 0.684009313583374 __________ Val Loss:: 0.9180386662483215\n",
      "Epoch:: [28]/[50] Step:: 10\n",
      "Train Loss:: 0.7007188200950623 __________ Val Loss:: 0.8591833710670471\n",
      "Epoch:: [29]/[50] Step:: 0\n",
      "Train Loss:: 0.6329929232597351 __________ Val Loss:: 0.8624810576438904\n",
      "Epoch:: [29]/[50] Step:: 10\n",
      "Train Loss:: 0.6055431962013245 __________ Val Loss:: 0.8620955944061279\n",
      "Epoch:: [30]/[50] Step:: 0\n",
      "Train Loss:: 0.6681537628173828 __________ Val Loss:: 0.8797886371612549\n",
      "Epoch:: [30]/[50] Step:: 10\n",
      "Train Loss:: 0.6031031012535095 __________ Val Loss:: 0.8774741291999817\n",
      "Epoch:: [31]/[50] Step:: 0\n",
      "Train Loss:: 0.5929502844810486 __________ Val Loss:: 0.8577812314033508\n",
      "Epoch:: [31]/[50] Step:: 10\n",
      "Train Loss:: 0.5328294634819031 __________ Val Loss:: 0.8485272526741028\n",
      "Epoch:: [32]/[50] Step:: 0\n",
      "Train Loss:: 0.5971478819847107 __________ Val Loss:: 0.8469171524047852\n",
      "Epoch:: [32]/[50] Step:: 10\n",
      "Train Loss:: 0.5570918321609497 __________ Val Loss:: 0.876495897769928\n",
      "Epoch:: [33]/[50] Step:: 0\n",
      "Train Loss:: 0.5989830493927002 __________ Val Loss:: 0.8824746012687683\n",
      "Epoch:: [33]/[50] Step:: 10\n",
      "Train Loss:: 0.5136777758598328 __________ Val Loss:: 0.8517540097236633\n",
      "Epoch:: [34]/[50] Step:: 0\n",
      "Train Loss:: 0.49233758449554443 __________ Val Loss:: 0.8516060709953308\n",
      "Epoch:: [34]/[50] Step:: 10\n",
      "Train Loss:: 0.506797194480896 __________ Val Loss:: 0.8499401211738586\n",
      "Epoch:: [35]/[50] Step:: 0\n",
      "Train Loss:: 0.5223721265792847 __________ Val Loss:: 0.8649024367332458\n",
      "Epoch:: [35]/[50] Step:: 10\n",
      "Train Loss:: 0.5079195499420166 __________ Val Loss:: 0.8753177523612976\n",
      "Epoch:: [36]/[50] Step:: 0\n",
      "Train Loss:: 0.572084367275238 __________ Val Loss:: 0.8725743293762207\n",
      "Epoch:: [36]/[50] Step:: 10\n",
      "Train Loss:: 0.48340579867362976 __________ Val Loss:: 0.9140576720237732\n",
      "Epoch:: [37]/[50] Step:: 0\n",
      "Train Loss:: 0.5178319811820984 __________ Val Loss:: 0.8797137141227722\n",
      "Epoch:: [37]/[50] Step:: 10\n",
      "Train Loss:: 0.5066646337509155 __________ Val Loss:: 0.8860465884208679\n",
      "Epoch:: [38]/[50] Step:: 0\n",
      "Train Loss:: 0.4611290991306305 __________ Val Loss:: 0.8693752884864807\n",
      "Epoch:: [38]/[50] Step:: 10\n",
      "Train Loss:: 0.47536662220954895 __________ Val Loss:: 0.8913584351539612\n",
      "Epoch:: [39]/[50] Step:: 0\n",
      "Train Loss:: 0.5101322531700134 __________ Val Loss:: 0.8735222220420837\n",
      "Epoch:: [39]/[50] Step:: 10\n",
      "Train Loss:: 0.4884635806083679 __________ Val Loss:: 0.9348651766777039\n",
      "Epoch:: [40]/[50] Step:: 0\n",
      "Train Loss:: 0.43206867575645447 __________ Val Loss:: 0.9255511164665222\n",
      "Epoch:: [40]/[50] Step:: 10\n",
      "Train Loss:: 0.43569543957710266 __________ Val Loss:: 0.8785468935966492\n",
      "Epoch:: [41]/[50] Step:: 0\n",
      "Train Loss:: 0.4721626341342926 __________ Val Loss:: 0.9165324568748474\n",
      "Epoch:: [41]/[50] Step:: 10\n",
      "Train Loss:: 0.4167710542678833 __________ Val Loss:: 0.9044246077537537\n",
      "Epoch:: [42]/[50] Step:: 0\n",
      "Train Loss:: 0.4128482937812805 __________ Val Loss:: 0.9057905077934265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:: [42]/[50] Step:: 10\n",
      "Train Loss:: 0.44062528014183044 __________ Val Loss:: 0.9131911396980286\n",
      "Epoch:: [43]/[50] Step:: 0\n",
      "Train Loss:: 0.3734813928604126 __________ Val Loss:: 0.930410623550415\n",
      "Epoch:: [43]/[50] Step:: 10\n",
      "Train Loss:: 0.38229450583457947 __________ Val Loss:: 0.936234176158905\n",
      "Epoch:: [44]/[50] Step:: 0\n",
      "Train Loss:: 0.3574378490447998 __________ Val Loss:: 0.9382214546203613\n",
      "Epoch:: [44]/[50] Step:: 10\n",
      "Train Loss:: 0.36602866649627686 __________ Val Loss:: 0.9540775418281555\n",
      "Epoch:: [45]/[50] Step:: 0\n",
      "Train Loss:: 0.428568571805954 __________ Val Loss:: 0.9900755882263184\n",
      "Epoch:: [45]/[50] Step:: 10\n",
      "Train Loss:: 0.39283305406570435 __________ Val Loss:: 0.961127758026123\n",
      "Epoch:: [46]/[50] Step:: 0\n",
      "Train Loss:: 0.3532962203025818 __________ Val Loss:: 1.0247721672058105\n",
      "Epoch:: [46]/[50] Step:: 10\n",
      "Train Loss:: 0.37701743841171265 __________ Val Loss:: 0.9924648404121399\n",
      "Epoch:: [47]/[50] Step:: 0\n",
      "Train Loss:: 0.36576569080352783 __________ Val Loss:: 1.0559719800949097\n",
      "Epoch:: [47]/[50] Step:: 10\n",
      "Train Loss:: 0.4056209325790405 __________ Val Loss:: 1.04643976688385\n",
      "Epoch:: [48]/[50] Step:: 0\n",
      "Train Loss:: 0.3291981816291809 __________ Val Loss:: 0.9896536469459534\n",
      "Epoch:: [48]/[50] Step:: 10\n",
      "Train Loss:: 0.3915504813194275 __________ Val Loss:: 1.0338685512542725\n",
      "Epoch:: [49]/[50] Step:: 0\n",
      "Train Loss:: 0.3571071922779083 __________ Val Loss:: 1.0361307859420776\n",
      "Epoch:: [49]/[50] Step:: 10\n",
      "Train Loss:: 0.3062611520290375 __________ Val Loss:: 1.040397047996521\n",
      "Epoch:: [50]/[50] Step:: 0\n",
      "Train Loss:: 0.37129852175712585 __________ Val Loss:: 1.0183240175247192\n",
      "Epoch:: [50]/[50] Step:: 10\n",
      "Train Loss:: 0.31958287954330444 __________ Val Loss:: 1.0215972661972046\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(params=model.parameters())\n",
    "# ignore the index for PAD\n",
    "criterion = nn.NLLLoss(ignore_index=training_set.tag_dict.get(\"<PAD>\"))  # type: ignore        \n",
    "run_validation_every_n_step = 10\n",
    "\n",
    "\n",
    "# fp16\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "epochs = 50\n",
    "for e in trange(epochs):\n",
    "\n",
    "    steps = 0\n",
    "    for batch in train_loader:\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "        \n",
    "        words = batch[\"words\"]\n",
    "        tags = batch[\"tags\"].long()\n",
    "        \n",
    "        # send data to device\n",
    "        words = words.to(device)\n",
    "        tags = tags.to(device)\n",
    "        \n",
    "        # zero out optimizer to accumulate new grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            logits = model(words)\n",
    "            logits = rearrange(logits, \"bs words probas -> bs probas words\")\n",
    "            \n",
    "            # loss\n",
    "            loss = criterion(logits, tags)\n",
    "        \n",
    "        \n",
    "        # ======== validation ==============\n",
    "        if steps % run_validation_every_n_step == 0:\n",
    "            val_losses = []\n",
    "            \n",
    "            # switch context\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    words = val_batch[\"words\"]\n",
    "                    tags = val_batch[\"tags\"].long()\n",
    "                    \n",
    "                    words = words.to(device)\n",
    "                    tags = tags.to(device)\n",
    "                    \n",
    "                    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                        logits = model(words)\n",
    "                        logits = rearrange(logits, \"bs words probas -> bs probas words\")\n",
    "                        val_loss = criterion(logits, tags)\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "                    \n",
    "                    # preds = torch.max(logits, dim=-1).indices\n",
    "\n",
    "                # log\n",
    "                print(f\"Epoch:: [{e + 1}]/[{epochs}] Step:: {steps}\")\n",
    "                print(f\"Train Loss:: {loss} __________ Val Loss:: {torch.mean(torch.tensor(val_losses))}\")\n",
    "        \n",
    "        # switch context\n",
    "        model.train()\n",
    "        scaler.scale(loss).backward()  # type: ignore\n",
    "        # loss.backward()\n",
    "        scaler.step(optimizer)\n",
    "        # optimizer.step()\n",
    "        scaler.update()\n",
    "        steps += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm looking for the overlap ratio here. \n",
    "# The idea is to find the ratio of how many of true tags overlap with pred\n",
    "# Sounds more like recall ............\n",
    "\n",
    "# unbatched\n",
    "def find_overlap(pred, true):\n",
    "    overlap = np.intersect1d(pred, true)\n",
    "    return overlap\n",
    "\n",
    "# unbatched\n",
    "def non_pad_count(x):\n",
    "    return x.shape[0] - np.count_nonzero(x == 17) \n",
    "\n",
    "\n",
    "# batched\n",
    "def mean_overlap_ratio(pred:torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
    "    ratios = list()\n",
    "    bs = pred.size()[0]\n",
    "    for i in range(bs):\n",
    "        p = pred[i].cpu().detach().numpy()\n",
    "        t = true[i].cpu().detach().numpy()\n",
    "\n",
    "        \n",
    "        overlap = find_overlap(p, t)\n",
    "        overlap_ratio = non_pad_count(overlap) / non_pad_count(t)\n",
    "        \n",
    "        ratios.append(overlap_ratio)\n",
    "    \n",
    "    # just sanity check\n",
    "    assert len(ratios) == bs\n",
    "    \n",
    "    # return the mean\n",
    "    return torch.mean(torch.tensor(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b3d205cb3940b49cde05b215e7d8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Overlap Ratio for all batches :: 0.49627581238746643\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader, device=device):\n",
    "    ratios = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            words = batch[\"words\"].to(device)\n",
    "            tags = batch[\"tags\"].long().to(device)\n",
    "        \n",
    "        \n",
    "            logits = model(words)\n",
    "        \n",
    "            preds = torch.max(logits, dim=-1).indices\n",
    "        \n",
    "            r = mean_overlap_ratio(preds, tags)\n",
    "            ratios.append(r)\n",
    "            \n",
    "    print(f\"Mean Overlap Ratio for all batches :: {torch.mean(torch.tensor(ratios))}\")\n",
    "\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdffddb8323643aabadf0ed4c6da97f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Overlap Ratio for all batches :: 0.554613471031189\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac663be645645be9ef4a62ebd87ca11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Overlap Ratio for all batches :: 0.488801509141922\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5383723a85d76e4e9cac0d136e01f6d8a177dc9dc4ee2b9a35edd51227ec1b17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
