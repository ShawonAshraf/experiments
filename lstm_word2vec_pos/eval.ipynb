{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/shawon/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "import gensim.downloader as dl\n",
    "\n",
    "pretrained_weights_name = \"word2vec-google-news-300\"\n",
    "model_dl_path = os.path.join(\n",
    "    dl.BASE_DIR, pretrained_weights_name, f\"{pretrained_weights_name}.gz\")\n",
    "\n",
    "\n",
    "if os.path.exists(model_dl_path):\n",
    "    # load model\n",
    "    print(f\"Loading model from {model_dl_path}\")\n",
    "    gnews_embeddings = dl.load(pretrained_weights_name)\n",
    "else:\n",
    "    # download\n",
    "    print(f\"Model will be downloaded at {model_dl_path}\")\n",
    "    gnews_embeddings = dl.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0faca737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawon/anaconda3/envs/exp/lib/python3.10/site-packages/gensim/models/keyedvectors.py:552: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# add PAD to embeddings\n",
    "\n",
    "# 0 padding, 300 embedding dims\n",
    "gnews_embeddings.add_vector(\"<PAD>\", np.zeros(300))\n",
    "\n",
    "# need it later for loading the embeddings in pytorch model\n",
    "padding_idx = len(gnews_embeddings.index_to_key) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d59c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class ConlluRowInfo:\n",
    "    word: str\n",
    "    lemma: str\n",
    "    pos: str\n",
    "\n",
    "    def __init__(self, word: str, lemma: str, pos: str) -> None:\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        rep = {\n",
    "            \"word\": self.word,\n",
    "            \"lemma\": self.lemma,\n",
    "            \"pos\": self.pos\n",
    "        }\n",
    "        return str(rep)\n",
    "\n",
    "\n",
    "class ConlluRow:\n",
    "    info: List[ConlluRowInfo]\n",
    "    # text: str\n",
    "\n",
    "    def __init__(self, infos: List[ConlluRowInfo]) -> None:\n",
    "        self.info = infos\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"info : {self.info}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4bc0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to define the torch dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import trange, tqdm\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class TweebankDataset(Dataset):\n",
    "    def __init__(self, filename, w2v_weights=gnews_embeddings) -> None:\n",
    "        self.filename = filename\n",
    "\n",
    "        self.w2v = w2v_weights\n",
    "        self.data = list()\n",
    "        self.__read_data()\n",
    "\n",
    "        self.MAX_SEQ_LEN = 50  # default value\n",
    "        # self.__find_max_seq_len()\n",
    "\n",
    "        self.UNIQUE_TAGS = ['PRON', 'NUM', 'NOUN', 'CCONJ', 'ADV', 'SCONJ',\n",
    "                            'ADP', 'AUX', 'PROPN', 'SYM', 'DET',\n",
    "                            'INTJ', 'PUNCT', 'X', 'ADJ', 'VERB', 'PART', \"<PAD>\"]\n",
    "        self.tag_dict = dict()\n",
    "        self.__encode_tags()\n",
    "\n",
    "        self.number_tags = len(self.UNIQUE_TAGS)\n",
    "\n",
    "        self.vocabulary = self.w2v.index_to_key  # type: ignore\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:\n",
    "        # ============== collect ===================\n",
    "        words = [i.word for i in self.data[idx].info]\n",
    "        # lemmas = [i.lemma for i in self.data[idx].info]\n",
    "        tags = [i.pos for i in self.data[idx].info]\n",
    "\n",
    "        # =================== convert using word2vec weights ==========\n",
    "        for idx in range(len(words)):\n",
    "            try:\n",
    "                w2v_idx = self.w2v.key_to_index[words[idx]]  # type: ignore\n",
    "            except KeyError:\n",
    "                w2v_idx = 0  # </s>\n",
    "            words[idx] = w2v_idx\n",
    "            tags[idx] = self.tag_dict[tags[idx]]\n",
    "\n",
    "        # ============== pad words ===============\n",
    "        # left pad\n",
    "        padded_words = np.zeros(self.MAX_SEQ_LEN, dtype=np.int32)\n",
    "        padded_words[-len(words):] = words\n",
    "\n",
    "        # ============== pad tags =================\n",
    "        padded_tags = np.ones(self.MAX_SEQ_LEN, dtype=np.int32) * \\\n",
    "            self.tag_dict.get(\"<PAD>\")  # type: ignore\n",
    "        padded_tags[-len(tags):] = tags\n",
    "\n",
    "        return {\n",
    "            \"words\": torch.tensor(padded_words),\n",
    "            \"tags\": torch.tensor(padded_tags),\n",
    "        }\n",
    "\n",
    "    def __find_max_seq_len(self) -> None:\n",
    "        seq_lens = []\n",
    "\n",
    "        for idx in range(len(self.data)):\n",
    "            words = [i.word for i in self.data[idx].info]\n",
    "            seq_lens.append(len(words))\n",
    "\n",
    "        self.MAX_SEQ_LEN = max(seq_lens)\n",
    "\n",
    "    def __encode_tags(self) -> None:\n",
    "        for idx, tag in enumerate(self.UNIQUE_TAGS):\n",
    "            self.tag_dict[tag] = idx\n",
    "\n",
    "    def __read_data(self) -> None:\n",
    "        with open(self.filename, \"r\") as f:\n",
    "            data = f.readlines()\n",
    "\n",
    "            # ============ read the text file =============\n",
    "            lines = list()\n",
    "            buffer = list()\n",
    "            for _, line in tqdm(enumerate(data)):\n",
    "                if line == \"\\n\":\n",
    "                    lines.append(buffer)\n",
    "                    buffer = []\n",
    "                else:\n",
    "                    buffer.append(line)\n",
    "\n",
    "            # ============== organize in objects ==============\n",
    "            for idx, line in tqdm(enumerate(lines)):\n",
    "                # from line index 2 and onwards\n",
    "                line_info = list()\n",
    "                for info in line[2:]:\n",
    "                    buffer = info.split(\"\\t\")\n",
    "\n",
    "                    try:\n",
    "                        word = buffer[1]\n",
    "                        lemma = buffer[2]\n",
    "                        tag = buffer[3]\n",
    "\n",
    "                        line_info.append(ConlluRowInfo(word, lemma, tag))\n",
    "\n",
    "                    except IndexError:\n",
    "                        print(buffer)\n",
    "\n",
    "                lines[idx] = ConlluRow(line_info)\n",
    "\n",
    "            self.data = lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58346a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66211d75c5cf43d6937e32ed1cd68bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893e85b471e64aea91feca7e95c494e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 128\n",
    "dl_args = {\n",
    "    \"pin_memory\": True,\n",
    "    \"batch_size\": bs\n",
    "}\n",
    "\n",
    "\n",
    "test_set = TweebankDataset(\n",
    "    \"/mnt/Others/experiments/datasets/Tweebank-dev/converted/en-ud-tweet-test.fixed.conllu\")\n",
    "\n",
    "test_loader = DataLoader(test_set, shuffle=False, **dl_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6544bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim: int, \n",
    "                 hidden_dim: int,  \n",
    "                 tagset_size: int,\n",
    "                 padding_idx=padding_idx, \n",
    "                 freeze_embeddings=True, \n",
    "                 w2v_weights=gnews_embeddings) -> None:\n",
    "        \n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.taget_size = tagset_size\n",
    "        \n",
    "        \n",
    "        embedding_tensors = torch.from_numpy(w2v_weights.vectors) # type: ignore        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(\n",
    "            embedding_tensors, freeze=freeze_embeddings, padding_idx=padding_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        \n",
    "        self.attention =  nn.MultiheadAttention(hidden_dim * 2, num_heads=4, dropout=0.1, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "\n",
    "        \n",
    "    def forward(self, words):\n",
    "        embeds = self.word_embeddings(words)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        \n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        relu_out = self.relu(attn_out)\n",
    "        \n",
    "        linear_out = self.linear(relu_out)\n",
    "\n",
    "        logits = F.log_softmax(linear_out, dim=-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f171f90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMTagger(\n",
       "  (word_embeddings): Embedding(3000001, 300, padding_idx=3000000)\n",
       "  (lstm): LSTM(300, 100, batch_first=True, bidirectional=True)\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (linear): Linear(in_features=200, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagset_size = len(test_set.UNIQUE_TAGS)\n",
    "model = LSTMTagger(embedding_dim=300, hidden_dim=100,  tagset_size=tagset_size)\n",
    "model.load_state_dict(torch.load(\"saved.pt\"))\n",
    "model = model.to(\"cpu\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0b44b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7656, 0.7339, 0.7796, 0.7399, 0.7522, 0.7324, 0.7642, 0.7308, 0.7316,\n",
      "        0.7638, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000])\n",
      "torch.Size([128])\n",
      "tensor(0.0585)\n"
     ]
    }
   ],
   "source": [
    "# on a single batch\n",
    "def categorical_accuracy(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
    "    # unvectorized, runs on a single data instance\n",
    "    def ca(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
    "        non_pad_idx = (true != 17).nonzero()\n",
    "        acc = pred[non_pad_idx].squeeze(0).eq(true[non_pad_idx])\n",
    "        \n",
    "        return acc.sum() / true[non_pad_idx].size()[0]\n",
    "    \n",
    "    bs = true.size()[0]\n",
    "    acc = torch.zeros(size=(bs,), dtype=torch.float32)\n",
    "    for i in range(bs):\n",
    "        p = pred[i]\n",
    "        t = true[i]\n",
    "        \n",
    "        acc[i] = ca(p, t)\n",
    "        \n",
    "    return acc.mean()\n",
    "\n",
    "def evaluate(model: LSTMTagger, data_loader: DataLoader) -> None:\n",
    "    TAG_PAD_IDX = 17\n",
    "    \n",
    "    all_accs = torch.zeros(size=(data_loader.batch_size, ), dtype=torch.float32) # type: ignore\n",
    "    \n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        words = batch[\"words\"]\n",
    "        tags = batch[\"tags\"].long()\n",
    "        \n",
    "        \n",
    "        logits = model(words)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        \n",
    "        # categorical acc\n",
    "        all_accs[idx] = categorical_accuracy(preds, tags)\n",
    "    \n",
    "    print(all_accs)\n",
    "    print(all_accs.size())\n",
    "    print(all_accs.mean())\n",
    "        \n",
    "        \n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe789a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where thomas realized that OOV needs to be handled. Anyways. Les go then. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5383723a85d76e4e9cac0d136e01f6d8a177dc9dc4ee2b9a35edd51227ec1b17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
