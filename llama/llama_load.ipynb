{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2491a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56c3853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b990637a6cc4674abfbdea97e89ceb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 1min 32s, total: 3min 2s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_path = \"/Users/shawon/Codes/llama-hf-converted/llama-2-7b\"\n",
    "model = AutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f684b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaModel(\n",
       "  (embed_tokens): Embedding(32000, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x LlamaDecoderLayer(\n",
       "      (self_attn): LlamaAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): LlamaMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): LlamaRMSNorm()\n",
       "      (post_attention_layernorm): LlamaRMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): LlamaRMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11ae8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d7b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Hurricane Otis was a compact yet devastating tropical cyclone which made landfall in October 2023 near Acapulco as a Category 5 hurricane. \n",
    "Otis was the first Pacific hurricane to make landfall at Category 5 intensity and surpassed Hurricane Patricia as the strongest landfalling Pacific hurricane on record. \n",
    "The fifteenth tropical storm, tenth hurricane, eighth major hurricane,[nb 1] and second Category 5 hurricane of the 2023 Pacific hurricane season, Otis originated from a disturbance several hundred miles south of the Gulf of Tehuantepec. \n",
    "Initially forecast to only be a weak tropical storm at peak intensity, Otis instead underwent explosive intensification to reach peak winds of 165 mph (270 km/h) and made landfall at peak intensity.\n",
    "Once inland, the hurricane rapidly weakened, before dissipating the following day.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296d8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode_plus(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9abc63ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 29871,    13, 29950,  1038, 26655,  8540,   275,   471,   263,\n",
       "         11071,  3447,  2906,   579,  1218, 21881,  5094, 16513,   607,  1754,\n",
       "          2982, 11950,   297,  5533, 29871, 29906, 29900, 29906, 29941,  2978,\n",
       "           319,  5030,   352,  1111,   408,   263, 17943, 29871, 29945,   298,\n",
       "          1038, 26655, 29889, 29871,    13, 29949, 28898,   471,   278,   937,\n",
       "         14328,   298,  1038, 26655,   304,  1207,  2982, 11950,   472, 17943,\n",
       "         29871, 29945, 26171,   322,  1190,  3364,   287,   379,  1038, 26655,\n",
       "          4121,  2200,   423,   408,   278,  4549,   342,  2982, 11950,   292,\n",
       "         14328,   298,  1038, 26655,   373,  2407, 29889, 29871,    13,  1576,\n",
       "          8461, 19839, 21881, 14280, 29892,   260,  9097,   298,  1038, 26655,\n",
       "         29892,   321, 18919,  4655,   298,  1038, 26655, 17094,  9877, 29871,\n",
       "         29896, 29962,   322,  1473, 17943, 29871, 29945,   298,  1038, 26655,\n",
       "           310,   278, 29871, 29906, 29900, 29906, 29941, 14328,   298,  1038,\n",
       "         26655,  4259, 29892,  8540,   275,  3978,   630,   515,   263, 29543,\n",
       "           749,  3196,  6893,  7800,  7062,   310,   278,   402, 16302,   310,\n",
       "          1920,  6905,  1647,  3135, 29889, 29871,    13, 15514,   368, 29821,\n",
       "           579,   304,   871,   367,   263,  8062, 21881, 14280,   472, 19224,\n",
       "         26171, 29892,  8540,   275,  2012,  1090, 29893,   296, 20389,   573,\n",
       "         12838,  2450,   304,  6159, 19224,  8805, 29879,   310, 29871, 29896,\n",
       "         29953, 29945,   286,   561,   313, 29906, 29955, 29900,  2383, 29914,\n",
       "         29882, 29897,   322,  1754,  2982, 11950,   472, 19224, 26171, 29889,\n",
       "            13, 26222,   297,  1049, 29892,   278,   298,  1038, 26655, 19328,\n",
       "          8062,  6419, 29892,  1434, 16317,   666,  1218,   278,  1494,  2462,\n",
       "         29889,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f7b5c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 232])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[\"input_ids\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676e1a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaModel(\n",
       "  (embed_tokens): Embedding(32000, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x LlamaDecoderLayer(\n",
       "      (self_attn): LlamaAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): LlamaMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): LlamaRMSNorm()\n",
       "      (post_attention_layernorm): LlamaRMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): LlamaRMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ece7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(**encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "995d5410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'past_key_values'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81cc1610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 232, 4096])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "527c01f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out.past_key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae9cb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "pooler = nn.Sequential(\n",
    "    nn.Linear(4096, 384),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05140afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden = out.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dd09c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pooled = pooler(last_hidden.mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d68020b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca6fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
