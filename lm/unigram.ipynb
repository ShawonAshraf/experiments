{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b15872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:14.797697962Z",
     "start_time": "2023-11-04T19:14:14.776090507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import download, read_data, tokenize_sentence, batch_tokenize_sentences\n",
    "        \n",
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aca550f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:14.842265735Z",
     "start_time": "2023-11-04T19:14:14.825301804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['First Citizen:',\n 'Before we proceed any further, hear me speak.',\n 'All:',\n 'Speak, speak.',\n 'First Citizen:',\n 'You are all resolved rather to die than to famish?',\n 'All:',\n 'Resolved. resolved.',\n 'First Citizen:',\n 'First, you know Caius Marcius is chief enemy to the people.']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data()\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7255b404",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:14.843351685Z",
     "start_time": "2023-11-04T19:14:14.839610810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['First', 'Citizen:']]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sents = batch_tokenize_sentences(data)\n",
    "tokenized_sents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1513a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:14.901772979Z",
     "start_time": "2023-11-04T19:14:14.842928241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "32777"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59facd3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:14.936471968Z",
     "start_time": "2023-11-04T19:14:14.885490045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32777 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2075d4847d446198c7ef81ab49cae95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_vocab(tokenized_sentences=tokenized_sents):\n",
    "    vocabulary = dict() # word to count mapping\n",
    "    \n",
    "    for _, sentence in tqdm(enumerate(tokenized_sentences), total=len(tokenized_sentences)):\n",
    "        for token in sentence:\n",
    "            if token in vocabulary.keys():\n",
    "                vocabulary[token] += 1.0\n",
    "            else:\n",
    "                vocabulary[token] = 0.0\n",
    "                \n",
    "\n",
    "    vocabulary[\"[OOV]\"] = 0.0\n",
    "    return vocabulary\n",
    "                \n",
    "                \n",
    "vocabulary = create_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efacd5ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:14.973207276Z",
     "start_time": "2023-11-04T19:14:14.932723943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "25672"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(list(vocabulary.keys()))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3afd342c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.055896550Z",
     "start_time": "2023-11-04T19:14:14.973384548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176998.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "def get_total_word_count(vocabulary):\n",
    "    total = reduce(lambda start, values: start + np.sum(values), vocabulary.values(), 0)\n",
    "    return total\n",
    "\n",
    "total_tokens = get_total_word_count(vocabulary)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49c9ba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.099479933Z",
     "start_time": "2023-11-04T19:14:15.063883016Z"
    }
   },
   "outputs": [],
   "source": [
    "def unigram_probabilities(vocabulary, total_tokens, vocab_size, smoothing=\"laplace\"):\n",
    "    probabilities = dict() # unigram -> probability\n",
    "    for k, v in vocabulary.items():\n",
    "        if smoothing:\n",
    "            probabilities[k] = (v + 1) / (float(total_tokens) + vocab_size)\n",
    "        \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "unigram_probs = unigram_probabilities(vocabulary, total_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7479a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.100597664Z",
     "start_time": "2023-11-04T19:14:15.099651065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4.934129372872157e-06"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_probs[\"[OOV]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cca24cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.100815836Z",
     "start_time": "2023-11-04T19:14:15.099893447Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sent_probs(sentence, unigram_probs=unigram_probs) -> np.ndarray:\n",
    "    if not isinstance(sentence, list):\n",
    "        # tokenize\n",
    "        tokens = tokenize_sentence(sentence)\n",
    "    else:\n",
    "        tokens = sentence\n",
    "        \n",
    "    \n",
    "    sentence_probs = []\n",
    "    for tok in tokens:\n",
    "        if tok in unigram_probs.keys():\n",
    "            sentence_probs.append(unigram_probs[tok])\n",
    "        else:\n",
    "            sentence_probs.append(unigram_probs[\"[OOV]\"])\n",
    "    \n",
    "    return np.array(sentence_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb0310da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.101181839Z",
     "start_time": "2023-11-04T19:14:15.100108549Z"
    }
   },
   "outputs": [],
   "source": [
    "def perplexity(prob):\n",
    "    product_prob = np.prod(prob)\n",
    "    return np.power(product_prob, (-1 / prob.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1a48fa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.102928306Z",
     "start_time": "2023-11-04T19:14:15.100414412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4c505473a794258afc67a283ec86536"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : First Citizen:\n",
      "Perplexity : 1335.4957137943866\n",
      "Probabilities : [0.00115952 0.00048354]\n",
      "\n",
      "Input : Manners maketh a man.\n",
      "Perplexity : 12557.003163608966\n",
      "Probabilities : [4.93412937e-06 4.93412937e-06 1.28780777e-02 1.28287364e-04]\n",
      "\n",
      "Input : Where's the ghost, Othello?\n",
      "Perplexity : 9271.229071152722\n",
      "Probabilities : [6.90778112e-05 2.68268614e-02 1.48023881e-05 4.93412937e-06]\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"First Citizen:\",\n",
    "    \"Manners maketh a man.\",\n",
    "    \"Where's the ghost, Othello?\"\n",
    "]\n",
    "\n",
    "def evaluate(test_inputs=test_inputs) -> None:\n",
    "    for _, ti in tqdm(enumerate(test_inputs), total=len(test_inputs)):\n",
    "        probs = get_sent_probs(ti)\n",
    "        p = perplexity(probs)\n",
    "        \n",
    "        print(f\"Input : {ti}\\nPerplexity : {p}\\nProbabilities : {probs}\\n\")\n",
    "        \n",
    "evaluate(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f08c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.401147414Z",
     "start_time": "2023-11-04T19:14:15.103292609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I absence verdict? enemies. Edmund sir: loved not, men curbs envied little shapes afflicts affection\n",
      "\n",
      "What! him; art need ears show prayer Patience object Claudio? Resolved. Capitol! others burn'd store-houses\n",
      "\n",
      "being I'ld need You Caius leave that book. good Worthy mine proud; business, revenge. If\n",
      "\n",
      "senators almost change One That letter muniments go'st common, verdict? Very prize A takes, them\n",
      "\n",
      "citizens, husewife with knees us. Their wake. saint bless cupboarding Nay, coffins Hang All: lady\n",
      "\n",
      "object us. What while since inclined. fear, away, soldier, Roman heart, dear: several poor worst\n",
      "\n",
      "talking She bear and That Roman cupboarding chance marriages; mantled care put nobility Have sword:\n",
      "\n",
      "competency Hark! To you, friends: prevail'd could help. Thanks. hand? not, Will show know't. had\n",
      "\n",
      "why dam answer? Have wholesome, work's, gods, since particularise done But surer, statutes mouths, soldier,\n",
      "say tale: Confess lion behind attends wisdoms, pikes, than talking deliberate, not Against rumour'd, feed\n",
      "\n",
      "jest sounds, lack poor. difference matter? business fought superfluity, answer'd-- Had eat, Though you'll authority\n",
      "\n",
      "Before comes, it's help. justice You, surfeits all, hear 'em below tell relieve fleer wont\n",
      "answer: now leanness ours. need relieved poor no. Under love general Unto cambric He's worse;\n",
      "\n",
      "hated attends which profession: speaks! some edicts proceed heard each, true; with themes Marcius; Sweet\n",
      "\n",
      "whole helms, could Fame, on idles leaden cry being crack, moon, itch veins else ne'er\n",
      "\n",
      "store-house yourselves? sick noise is world proceeds gates yet: indeed! enough: approved taunts. sincerely: means\n",
      "you, off! abhorring. picture-like mules, country? content singularity, Would rebellion, wager discovery. no almost asunder\n",
      "\n",
      "ha' Alack, foremost: Second utter, maliciously. business hate, Corn receipt; Set shop virtue. stored cares,\n",
      "\n",
      "our spurn along. our The peopled if think, Thus citizens. go tale: rash toe? here--\n",
      "\n",
      "people court, kingly-crowned Caius one resolved would fell basest, might rakes: helms enemy done Upon\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def generate(n_tokens, unigram_probs=unigram_probs, trials=50):\n",
    "    words = list()\n",
    "    probs = list()\n",
    "    \n",
    "    for k, v in unigram_probs.items():\n",
    "        words.append(k)\n",
    "        probs.append(v)\n",
    "        \n",
    "        \n",
    "    assert len(words) == len(probs)\n",
    "    \n",
    "    dist = softmax(probs, axis=-1)\n",
    "    logits = np.random.multinomial(trials, dist, n_tokens)\n",
    "    \n",
    "    logits = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    indexes = logits.tolist()\n",
    "    \n",
    "    \n",
    "    out  = \" \".join(words[i] for i in indexes)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(20):\n",
    "    print(generate(15))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65813c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T19:14:15.401460277Z",
     "start_time": "2023-11-04T19:14:15.398576959Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
