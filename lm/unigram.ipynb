{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b15872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import download, read_data, tokenize_sentence, batch_tokenize_sentences\n",
    "        \n",
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aca550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " 'First Citizen:',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " 'All:',\n",
       " 'Resolved. resolved.',\n",
       " 'First Citizen:',\n",
       " 'First, you know Caius Marcius is chief enemy to the people.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data()\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7255b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['First', 'Citizen:']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sents = batch_tokenize_sentences(data)\n",
    "tokenized_sents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1513a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32777"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59facd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c3073ba87c40aabe7c8fd6f923a0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_vocab(tokenized_sentences=tokenized_sents):\n",
    "    vocabulary = dict() # word to count mapping\n",
    "    \n",
    "    for _, sentence in tqdm(enumerate(tokenized_sentences), total=len(tokenized_sentences)):\n",
    "        for token in sentence:\n",
    "            if token in vocabulary.keys():\n",
    "                vocabulary[token] += 1.0\n",
    "            else:\n",
    "                vocabulary[token] = 0.0\n",
    "                \n",
    "\n",
    "    vocabulary[\"[OOV]\"] = 0.0\n",
    "    return vocabulary\n",
    "                \n",
    "                \n",
    "vocabulary = create_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efacd5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25672"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(list(vocabulary.keys()))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3afd342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176998.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "def get_total_word_count(vocabulary):\n",
    "    total = reduce(lambda start, values: start + np.sum(values), vocabulary.values(), 0)\n",
    "    return total\n",
    "\n",
    "total_tokens = get_total_word_count(vocabulary)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a49c9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_probabilities(vocabulary, total_tokens, vocab_size, smoothing=\"laplace\"):\n",
    "    probabilities = dict() # unigram -> probability\n",
    "    for k, v in vocabulary.items():\n",
    "        if smoothing:\n",
    "            probabilities[k] = (v + 1) / (float(total_tokens) + vocab_size)\n",
    "        \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "unigram_probs = unigram_probabilities(vocabulary, total_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae7479a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.934129372872157e-06"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_probs[\"[OOV]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cca24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_probs(sentence, unigram_probs=unigram_probs) -> np.ndarray:\n",
    "    if not isinstance(sentence, list):\n",
    "        # tokenize\n",
    "        tokens = tokenize_sentence(sentence)\n",
    "    else:\n",
    "        tokens = sentence\n",
    "        \n",
    "    \n",
    "    sentence_probs = []\n",
    "    for tok in tokens:\n",
    "        if tok in unigram_probs.keys():\n",
    "            sentence_probs.append(unigram_probs[tok])\n",
    "        else:\n",
    "            sentence_probs.append(unigram_probs[\"[OOV]\"])\n",
    "    \n",
    "    return np.array(sentence_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb0310da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(prob):\n",
    "    product_prob = np.prod(prob)\n",
    "    return np.power(product_prob, (-1 / prob.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1a48fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aac0135d6c4231998147f89a31f964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : First Citizen:\n",
      "Perplexity : 1335.4957137943866\n",
      "Probabilities : [0.00115952 0.00048354]\n",
      "\n",
      "Input : Manners maketh a man.\n",
      "Perplexity : 12557.003163608966\n",
      "Probabilities : [4.93412937e-06 4.93412937e-06 1.28780777e-02 1.28287364e-04]\n",
      "\n",
      "Input : Where's the ghost, Othello?\n",
      "Perplexity : 9271.229071152722\n",
      "Probabilities : [6.90778112e-05 2.68268614e-02 1.48023881e-05 4.93412937e-06]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"First Citizen:\",\n",
    "    \"Manners maketh a man.\",\n",
    "    \"Where's the ghost, Othello?\"\n",
    "]\n",
    "\n",
    "def evaluate(test_inputs=test_inputs) -> None:\n",
    "    for _, ti in tqdm(enumerate(test_inputs), total=len(test_inputs)):\n",
    "        probs = get_sent_probs(ti)\n",
    "        p = perplexity(probs)\n",
    "        \n",
    "        print(f\"Input : {ti}\\nPerplexity : {p}\\nProbabilities : {probs}\\n\")\n",
    "        \n",
    "evaluate(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6f08c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "former devour out at Soft! Be-mock noble flour famish? Should hunt. highest! Not an-hungry; senate;\n",
      "\n",
      "dismiss'd poorest, not--'Sdeath! please us, was Note matter, 'We giddy wholesome, wall, war the tauntingly\n",
      "\n",
      "maliciously. maliciously. her maliciously. love minute own Against Against to Which rakes: profits, flatterers, mouths,\n",
      "\n",
      "inkling Appear it's die account What! once, covetous. generosity, eat reputed comeliness Marcius, No bale.\n",
      "\n",
      "about, us, store-houses were sprang inventory hear blood general SICINIUS: where cannot sun: more, a\n",
      "\n",
      "Bolingbroke's answer'd: bear You mother virtue. work's, fob likely then? fight vantage. days one link\n",
      "\n",
      "wholesome the troth, fought; What show senate, brain; need virtue. good. good us, All superfluity,\n",
      "\n",
      "hereafter. proceeds folly. absence famously, guess in Lady food o'er, fob afflicts statutes kill awe,\n",
      "\n",
      "chief help usest corn looked guard well. outweighs common, issue partly I'll darts, proud. appetite,\n",
      "\n",
      "sink yield strongest you'll gaze rushes. sufferance sir: him mutiners, true-bred! famish? who, Come, inventory\n",
      "\n",
      "all why that spare Where to transported whence What affright enemy Strike time fort, further,\n",
      "\n",
      "their slaves, famish, What hear proud. over dog have than humanely; sir, violent worthy price.\n",
      "\n",
      "purpose, soft-conscienced apply am strong nature, tell only: walk, Second vice will toe? 'tis country?\n",
      "\n",
      "walk, when live coffers, For, people was seem not--'Sdeath! gods, statue, there's this, second men\n",
      "\n",
      "speak. have should competency lean-look'd I'll But, Resolved. What! soft-conscienced battle; things at Caius prating\n",
      "\n",
      "cousin'? foxes, peace are yourselves? any proceed ingratitude, authority any receipt; says further, call bats\n",
      "\n",
      "was well; that come. members know't, sir: eat honours, Tullus' curbs will men our on\n",
      "\n",
      "body. ten eye, digest answer: speak. than Come, many leanness body,-- entered our before away,\n",
      "\n",
      "me true-meant son? stored. veil'd us: an strange. bread, demerits suffer answer'd, pluck instruct, poor\n",
      "\n",
      "nature, dressings, stiff royal. edicts Ye're devise, verdict? crutch bats father's must rebellion, sufferance prating\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def generate(n_tokens, unigram_probs=unigram_probs, trials=50):\n",
    "    words = list()\n",
    "    probs = list()\n",
    "    \n",
    "    for k, v in unigram_probs.items():\n",
    "        words.append(k)\n",
    "        probs.append(v)\n",
    "        \n",
    "        \n",
    "    assert len(words) == len(probs)\n",
    "    \n",
    "    dist = softmax(probs, axis=-1)\n",
    "    logits = np.random.multinomial(trials, dist, n_tokens)\n",
    "    \n",
    "    logits = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    indexes = logits.tolist()\n",
    "    \n",
    "    \n",
    "    out  = \" \".join(words[i] for i in indexes)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(20):\n",
    "    print(generate(15))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65813c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
