{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b15872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import download, read_data, tokenize_sentence, batch_tokenize_sentences\n",
    "        \n",
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aca550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " 'First Citizen:',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " 'All:',\n",
       " 'Resolved. resolved.',\n",
       " 'First Citizen:',\n",
       " 'First, you know Caius Marcius is chief enemy to the people.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data()\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7255b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['First', 'Citizen:']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sents = batch_tokenize_sentences(data)\n",
    "tokenized_sents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1513a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32777"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59facd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e5b7169bf24e02b0c5d3ec878e7615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_vocab(tokenized_sentences=tokenized_sents):\n",
    "    vocabulary = dict() # word to count mapping\n",
    "    \n",
    "    for _, sentence in tqdm(enumerate(tokenized_sentences), total=len(tokenized_sentences)):\n",
    "        for token in sentence:\n",
    "            if token in vocabulary.keys():\n",
    "                vocabulary[token] += 1.0\n",
    "            else:\n",
    "                vocabulary[token] = 0.0\n",
    "                \n",
    "\n",
    "    vocabulary[\"[OOV]\"] = 0.0\n",
    "    return vocabulary\n",
    "                \n",
    "                \n",
    "vocabulary = create_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efacd5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25672"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(list(vocabulary.keys()))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3afd342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176998.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "def get_total_word_count(vocabulary):\n",
    "    total = reduce(lambda start, values: start + np.sum(values), vocabulary.values(), 0)\n",
    "    return total\n",
    "\n",
    "total_tokens = get_total_word_count(vocabulary)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49c9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_probabilities(vocabulary, total_tokens, vocab_size, smoothing=\"laplace\"):\n",
    "    probabilities = dict() # unigram -> probability\n",
    "    for k, v in vocabulary.items():\n",
    "        if smoothing:\n",
    "            probabilities[k] = (v + 1) / (float(total_tokens) + vocab_size)\n",
    "        \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "unigram_probs = unigram_probabilities(vocabulary, total_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7479a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.934129372872157e-06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_probs[\"[OOV]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cca24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_probs(sentence, unigram_probs=unigram_probs) -> np.ndarray:\n",
    "    if not isinstance(sentence, list):\n",
    "        # tokenize\n",
    "        tokens = tokenize_sentence(sentence)\n",
    "    else:\n",
    "        tokens = sentence\n",
    "        \n",
    "    \n",
    "    sentence_probs = []\n",
    "    for tok in tokens:\n",
    "        if tok in unigram_probs.keys():\n",
    "            sentence_probs.append(unigram_probs[tok])\n",
    "        else:\n",
    "            sentence_probs.append(unigram_probs[\"[OOV]\"])\n",
    "    \n",
    "    return np.array(sentence_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb0310da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(prob):\n",
    "    product_prob = np.prod(prob)\n",
    "    return np.power(product_prob, (-1 / prob.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1a48fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1537ec8b42cb4de7bcb00222e450f706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : First Citizen:\n",
      "Perplexity : 1335.4957137943866\n",
      "Probabilities : [0.00115952 0.00048354]\n",
      "\n",
      "Input : Manners maketh a man.\n",
      "Perplexity : 12557.003163608966\n",
      "Probabilities : [4.93412937e-06 4.93412937e-06 1.28780777e-02 1.28287364e-04]\n",
      "\n",
      "Input : Where's the ghost, Othello?\n",
      "Perplexity : 9271.229071152722\n",
      "Probabilities : [6.90778112e-05 2.68268614e-02 1.48023881e-05 4.93412937e-06]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"First Citizen:\",\n",
    "    \"Manners maketh a man.\",\n",
    "    \"Where's the ghost, Othello?\"\n",
    "]\n",
    "\n",
    "def evaluate(test_inputs=test_inputs) -> None:\n",
    "    for _, ti in tqdm(enumerate(test_inputs), total=len(test_inputs)):\n",
    "        probs = get_sent_probs(ti)\n",
    "        p = perplexity(probs)\n",
    "        \n",
    "        print(f\"Input : {ti}\\nPerplexity : {p}\\nProbabilities : {probs}\\n\")\n",
    "        \n",
    "evaluate(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f08c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def generate(n_tokens, unigram_probs=unigram_probs, trials=50):\n",
    "    words = list()\n",
    "    probs = list()\n",
    "    \n",
    "    for k, v in unigram_probs.items():\n",
    "        words.append(k)\n",
    "        probs.append(v)\n",
    "        \n",
    "        \n",
    "    assert len(words) == len(probs)\n",
    "    \n",
    "    dist = softmax(probs, axis=-1)\n",
    "    logits = np.random.multinomial(trials, dist, n_tokens)\n",
    "    \n",
    "    logits = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    indexes = logits.tolist()\n",
    "    \n",
    "    \n",
    "    out  = \" \".join(words[i] for i in indexes)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76d9a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well send pikes, arms, instruction. There famously, Citizen: Marcius? ever But, virtue. pot, Worthy It\n",
      "\n",
      "they let to Rome:' attends Ye're thirst much said than envying They'll me,-- business!' patricians\n",
      "\n",
      "gaze wholesome, their enough: run cracking 'Though else then partly did accusers, help. fortune knees\n",
      "\n",
      "arms Speak, Marcius? minute all speak could backs appetite already. citizens, wall, less this had;\n",
      "\n",
      "friends,'--this three-and-twenty, shop would words shadow ne'er countrymen, 'tis heart, grave surplus, nor dog revenge.\n",
      "\n",
      "clubs? folly. granted cannot, upon; you, sufferance are you Very yet then, once misery, finds\n",
      "\n",
      "Nay, former sufferance the piercing already. All: so! ridiculous Whereby about shall to this rates;\n",
      "\n",
      "prevail'd burn'd us, hares; commonalty. Some cared madam. XI: We For, puts very to barren\n",
      "\n",
      "their sufferance must misery, an it stand might proceeds accusations; things country lord o' neighbours,\n",
      "\n",
      "vile Rome:' Citizen: think rather well: did rates; altitude treads 'Though yield deliver. off! can\n",
      "\n",
      "relieved might finds Verily, Ye? upon; gain proceed let rakes: Brutus, him, Ay, whole muniments\n",
      "\n",
      "speak pale--they kings' Rebell'd We thousands are speaks! gold, benefit Before support tailor I' win\n",
      "\n",
      "Resolved. who most But relieved some seat malicious, his slander MENENIUS: Second Ye're but, Should\n",
      "\n",
      "Of pardon,-- trusts is. Should born vantage. me need us, galled disdains countrymen, neighbours, intend\n",
      "\n",
      "charitable we him. city minister the appetite, good. rogues, former We an Which that do,\n",
      "\n",
      "Volsces cry enough! yonder, be us field gods, fault, Appear awe, trophy: Either patricians body:\n",
      "\n",
      "ever choice: belly He's revenge citizens, answer'd-- help give hath think, thence; fit seeking? relieve\n",
      "\n",
      "he, find Marcius? Where bard course people--which we Of guess thousand about people. brook treads\n",
      "\n",
      "matter, sir: all, friends,' little-- think a First where thither strike seen partly war? corn\n",
      "\n",
      "Began object in Verona? who, friends,'--this Is't risen: arms, the fortnight about account man, fight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    print(generate(15))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65813c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
