{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b15872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import download, read_data, tokenize_sentence, batch_tokenize_sentences\n",
    "        \n",
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aca550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " 'First Citizen:',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " 'All:',\n",
       " 'Resolved. resolved.',\n",
       " 'First Citizen:',\n",
       " 'First, you know Caius Marcius is chief enemy to the people.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data()\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7255b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['First', 'Citizen:']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sents = batch_tokenize_sentences(data)\n",
    "tokenized_sents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1513a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32777"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59facd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eede7bab466a497e805948b1c0afefaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_vocab(tokenized_sentences=tokenized_sents):\n",
    "    vocabulary = dict() # word to count mapping\n",
    "    \n",
    "    for _, sentence in tqdm(enumerate(tokenized_sentences), total=len(tokenized_sentences)):\n",
    "        for token in sentence:\n",
    "            if token in vocabulary.keys():\n",
    "                vocabulary[token] += 1.0\n",
    "            else:\n",
    "                vocabulary[token] = 0.0\n",
    "                \n",
    "\n",
    "    vocabulary[\"[OOV]\"] = 0.0\n",
    "    return vocabulary\n",
    "                \n",
    "                \n",
    "vocabulary = create_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efacd5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25672"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(list(vocabulary.keys()))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3afd342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176998.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "def get_total_word_count(vocabulary):\n",
    "    total = reduce(lambda start, values: start + np.sum(values), vocabulary.values(), 0)\n",
    "    return total\n",
    "\n",
    "total_tokens = get_total_word_count(vocabulary)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49c9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def unigram_probabilities(vocabulary, total_tokens, vocab_size, smoothing=\"laplace\"):\n",
    "    probabilities = dict() # unigram -> probability\n",
    "    for k, v in vocabulary.items():\n",
    "        if smoothing:\n",
    "            probabilities[k] = (v + 1) / (float(total_tokens) + vocab_size)\n",
    "        \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def normalize_probabilities(unigram_probs):\n",
    "    words = list()\n",
    "    probs = list()\n",
    "    \n",
    "    for k, v in unigram_probs.items():\n",
    "        words.append(k)\n",
    "        probs.append(v)\n",
    "        \n",
    "    normalised = softmax(probs, axis=-1).tolist()\n",
    "    d = dict()\n",
    "    for w, p in zip(words, normalised):\n",
    "        d[w] = p\n",
    "        \n",
    "    return d\n",
    "    \n",
    "    \n",
    "\n",
    "unigram_probs = unigram_probabilities(vocabulary, total_tokens, vocab_size)\n",
    "unigram_probs = normalize_probabilities(unigram_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7479a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.895161667619404e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_probs[\"[OOV]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cca24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_probs(sentence, unigram_probs=unigram_probs) -> np.ndarray:\n",
    "    if not isinstance(sentence, list):\n",
    "        # tokenize\n",
    "        tokens = tokenize_sentence(sentence)\n",
    "    else:\n",
    "        tokens = sentence\n",
    "        \n",
    "    \n",
    "    sentence_probs = []\n",
    "    for tok in tokens:\n",
    "        if tok in unigram_probs.keys():\n",
    "            sentence_probs.append(unigram_probs[tok])\n",
    "        else:\n",
    "            sentence_probs.append(unigram_probs[\"[OOV]\"])\n",
    "    \n",
    "    return np.array(sentence_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb0310da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(prob):\n",
    "    product_prob = np.prod(prob)\n",
    "    return np.power(product_prob, (-1 / prob.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1a48fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedb0c9abee24f4ea390da2e613b17e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : First Citizen:\n",
      "Perplexity : 25651.919488240488\n",
      "Probabilities : [3.89966157e-05 3.89702638e-05]\n",
      "\n",
      "Input : Manners maketh a man.\n",
      "Perplexity : 25589.59636479137\n",
      "Probabilities : [3.89516167e-05 3.89516167e-05 3.94562878e-05 3.89564218e-05]\n",
      "\n",
      "Input : Where's the ghost, Othello?\n",
      "Perplexity : 25500.830398334332\n",
      "Probabilities : [3.89541153e-05 4.00105114e-05 3.89520011e-05 3.89516167e-05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"First Citizen:\",\n",
    "    \"Manners maketh a man.\",\n",
    "    \"Where's the ghost, Othello?\"\n",
    "]\n",
    "\n",
    "def evaluate(test_inputs=test_inputs) -> None:\n",
    "    for _, ti in tqdm(enumerate(test_inputs), total=len(test_inputs)):\n",
    "        probs = get_sent_probs(ti)\n",
    "        p = perplexity(probs)\n",
    "        \n",
    "        print(f\"Input : {ti}\\nPerplexity : {p}\\nProbabilities : {probs}\\n\")\n",
    "        \n",
    "evaluate(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f08c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n_tokens, unigram_probs=unigram_probs, trials=50):\n",
    "    words = list()\n",
    "    probs = list()\n",
    "    \n",
    "    for k, v in unigram_probs.items():\n",
    "        words.append(k)\n",
    "        probs.append(v)\n",
    "        \n",
    "        \n",
    "    assert len(words) == len(probs)\n",
    "    \n",
    "    logits = np.random.multinomial(trials, probs, n_tokens)\n",
    "    \n",
    "    logits = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    indexes = logits.tolist()\n",
    "    \n",
    "    \n",
    "    out  = \" \".join(words[i] for i in indexes)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76d9a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hire. And, honours. us, Under it; doors! than hunger may end: Thanks. even strike evil.\n",
      "\n",
      "kind this They Marcius people Piercing Marcius altitude men be any price. Cominius' persuaded; court,\n",
      "\n",
      "You rise, know your act sick, O' leg, First, yourselves. yet, live lady will; sir:\n",
      "\n",
      "end: Come, Second lungs, strange might only moved, speak. am trumpeter. looked Will senate; then?\n",
      "\n",
      "folly. country? sell time A citizens. came marriages; superfluity, veins bear curbs known citizens, tell\n",
      "\n",
      "we with love of us first: people. send want answer. First thirst must is, moon.\n",
      "\n",
      "did wives, surfeits aunt be if become know't, change seem'd, ere he's let lowly hand?\n",
      "\n",
      "us! love revenge Strike he, statutes Till petty The general's appetite heaven needs matter? come.\n",
      "\n",
      "body. them, you. bent: especially Second takes, that, unapt Citizen: was run, place idle sigh'd\n",
      "\n",
      "Lartius, ne'er poison'd proud. know't. indeed fragments! citizens, hand? company bats grown Why, present, fathers\n",
      "\n",
      "What thrives Above fit yourself remain You He's matter, hear body. where senate; first, wholesome\n",
      "\n",
      "patricians Ay, in followed. even need come. shall, senators Will You patricians some yield ruth,\n",
      "\n",
      "Messenger: hue citizens found such speak. Courtsied some intend body: gripe We far you! shunning\n",
      "\n",
      "feed curs, if sacrifice. that, Would many first broke speak. that partly I'ld they-- Second\n",
      "\n",
      "We wit: he's Leads basest, With repetition. grave say purpose, follow: price. object steed pinn'd\n",
      "\n",
      "countrymen, fear! know't, The misery, BRUTUS: malign Ulysses' 'Come folly. rivers accused link Capitol! Are\n",
      "\n",
      "tongue hast fit some Were it, battle; famish, one midst held rebellion, soft-conscienced choice. from\n",
      "\n",
      "daily Care whole soft-conscienced war friends,' verdict? desires city gnaw curse senators a store, gracious,\n",
      "\n",
      "both, He's jewel. sufferance hits honour receipt; Roman: need transported death fitly wholesome, they attain'd\n",
      "\n",
      "stand'st than enemies. done: have prating parts Ay, by famish, hair, express authority troop? so!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    print(generate(15))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65813c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
